{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e metatrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pet-neighbors-convert --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"v1.5\"\n",
    "TYPE = \"cleaned-pbc\"\n",
    "OUTPUT_FOLDER = f\"{DATASET_FOLDER}_{TYPE}_merged\"\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ase.io import read, write\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "\n",
    "for split in SPLITS:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, f\"{split}.xyz\")\n",
    "    all_atoms = []\n",
    "\n",
    "    for root, _, _files in os.walk(DATASET_FOLDER):\n",
    "        target_file = os.path.join(root, TYPE, f\"{split}.xyz\")\n",
    "\n",
    "        if os.path.exists(target_file):\n",
    "            atoms_list = read(target_file, index=\":\")\n",
    "            all_atoms.extend(atoms_list)\n",
    "\n",
    "    write(output_path, all_atoms, format=\"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatrain.experimental.nativepet import NativePET\n",
    "\n",
    "model = NativePET.load_checkpoint(\"pet-mad-latest.ckpt\").eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatensor.torch.atomistic import ModelOutput\n",
    "\n",
    "from metatrain.utils.data import read_systems\n",
    "from metatrain.utils.neighbor_lists import get_system_with_neighbor_lists\n",
    "\n",
    "from metatensor.torch.atomistic import ModelOutput\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_llf(dataset_path):\n",
    "    systems = read_systems(dataset_path)\n",
    "    print(\"systems\", len(systems))\n",
    "\n",
    "    neighbor_list_options = model.requested_neighbor_lists()\n",
    "\n",
    "    outputs = {\n",
    "        \"energy\": ModelOutput(per_atom=False),\n",
    "        \"mtt::aux::energy_last_layer_features\": ModelOutput(per_atom=False),\n",
    "    }\n",
    "\n",
    "    all_last_layer_features = []\n",
    "\n",
    "    for i in range(0, len(systems), BATCH_SIZE):\n",
    "        batch_systems = systems[i : i + BATCH_SIZE]\n",
    "\n",
    "        processed_batch = []\n",
    "        for system in batch_systems:\n",
    "            system_with_nl = get_system_with_neighbor_lists(\n",
    "                system, neighbor_list_options\n",
    "            )\n",
    "            processed_batch.append(\n",
    "                system_with_nl.to(dtype=torch.float32, device=DEVICE)\n",
    "            )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_predictions = model(processed_batch, outputs)\n",
    "            batch_features = (\n",
    "                batch_predictions[\"mtt::aux::energy_last_layer_features\"].block().values\n",
    "            )\n",
    "\n",
    "        all_last_layer_features.append(batch_features)\n",
    "\n",
    "        print(f\"Processed batch {i//BATCH_SIZE + 1}/{(len(systems)-1)//BATCH_SIZE + 1}\")\n",
    "\n",
    "    last_layer_features = torch.cat(all_last_layer_features, dim=0)\n",
    "    print(\"last_layer_features\", len(last_layer_features))\n",
    "\n",
    "    return last_layer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFF_OUTPUT_FOLDER = f\"{DATASET_FOLDER}_cleaned-pbc_llfs\"\n",
    "\n",
    "os.makedirs(LFF_OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"Processing {split}...\")\n",
    "    llfs_tensor = get_llf(os.path.join(\"v1.5_cleaned-pbc_merged\", f\"{split}.xyz\"))\n",
    "\n",
    "    torch.save(llfs_tensor, os.path.join(LFF_OUTPUT_FOLDER, f\"{split}.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemiscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
